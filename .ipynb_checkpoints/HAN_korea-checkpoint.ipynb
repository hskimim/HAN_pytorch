{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 페이지는 Zichao Yang1, Diyi Yang1, Chris Dyer1, Xiaodong He2, Alex Smola1, Eduard Hovy1 (2016), \"Hierarchical Attention Networks for Document Classification\" 논문에 관한 구현입니다.\n",
    "http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "\n",
    "__________________________________\n",
    "\n",
    "references : \n",
    "- https://github.com/pandeykartikey/Hierarchical-Attention-Network/blob/master/HAN%20yelp.ipynb\n",
    "- https://github.com/vietnguyen91/Hierarchical-attention-networks-pytorch/blob/master/src/utils.py\n",
    "- https://github.com/EdGENetworks/attention-networks-for-classification/blob/master/attention_model_validation_experiments.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from collections import defaultdict,Counter\n",
    "import pickle\n",
    "\n",
    "from termcolor import colored, cprint\n",
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chmod(\"yelp_academic_dataset_review.json\", 0o777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_iter = pd.read_json('yelp_academic_dataset_review.json',lines=True,chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685900, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(df_iter,axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.head(1000000)\n",
    "df.shape\n",
    "# 데이터가 너무 많아서 100만개만 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string, max_seq_len):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = BeautifulSoup(string, \"lxml\").text\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\\"\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\\"s\", \" \\\"s\", string)\n",
    "    string = re.sub(r\"\\\"ve\", \" \\\"ve\", string)\n",
    "    string = re.sub(r\"n\\\"t\", \" n\\\"t\", string)\n",
    "    string = re.sub(r\"\\\"re\", \" \\\"re\", string)\n",
    "    string = re.sub(r\"\\\"d\", \" \\\"d\", string)\n",
    "    string = re.sub(r\"\\\"ll\", \" \\\"ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    s =string.strip().lower().split(\" \")\n",
    "    if len(s) > max_seq_len:\n",
    "        return s[0:max_seq_len] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "Y = (df['stars'] - 1)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X,Y, test_size=0.33, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501213    Quite disturbed by no team work, seems to be s...\n",
       "805861    Based on flavour of the food and quality of th...\n",
       "882726    My sister was visiting and we were looking for...\n",
       "371658    Some of the best food in the area. Great selec...\n",
       "409957    the food is always great!, lots of vegetarian ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create3DList(data, max_sent_len,max_seq_len):\n",
    "    x = []; x1 = []\n",
    "    for seq in sent_tokenize(data) :\n",
    "        x1.append(clean_str(seq,max_sent_len))\n",
    "    x.append(x1[:max_seq_len])\n",
    "    return x\n",
    "\n",
    "# max_sent_len : 한 문장에 들어가는 단어의 갯수\n",
    "# max_seq_len : 한 문서에 들어가는 문장의 갯수\n",
    "max_sent_len = 12; max_seq_len = 25\n",
    "\n",
    "x_train = X_train.apply(lambda x : create3DList(x,max_sent_len,max_seq_len))\n",
    "x_test = X_test.apply(lambda x : create3DList(x,max_sent_len,max_seq_len))\n",
    "\n",
    "print(\"x_train: {}\".format(len(x_train)))\n",
    "print(\"x_test: {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.tolist()\n",
    "x_test = x_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670000, 330000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_idx_dict = {'<unk>':0,'<pad>':1}\n",
    "\n",
    "for idx,doc in enumerate(x_train) : \n",
    "    if idx % 1000 == 0 : print(\"{}번째 문서 처리 중이며 word_to_idx_dict의 길이는 {}입니다.\"\\\n",
    "                               .format(idx,len(word_to_idx_dict)))\n",
    "    for sent in doc[0] : \n",
    "        for word in sent : \n",
    "            if word not in word_to_idx_dict.keys() :                 \n",
    "                word_to_idx_dict[word] = len(word_to_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_freq_dict = defaultdict(int)\n",
    "\n",
    "for idx,doc in enumerate(x_train) : \n",
    "    if idx % 1000 == 0 : print(\"{}번째 문서 처리 중이며 word_to_freq_dict의 길이는 {}입니다.\"\\\n",
    "                               .format(idx,len(word_to_freq_dict)))\n",
    "    for sent in doc[0] : \n",
    "        for word in sent : \n",
    "            word_to_freq_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_word_dict = {idx:val for val,idx in word_to_idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(obj,name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(word_to_idx_dict,'word_to_idx_dict')\n",
    "save_obj(word_to_freq_dict,'word_to_freq_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_to_idx(doc,min_freq=5) : \n",
    "    \"\"\"\n",
    "    doc : train or validation or test datasets which are composed with list within list\n",
    "    \"\"\"\n",
    "\n",
    "    min_freq_ls = [[word for word in sent if word_to_freq_dict[word] > min_freq] for sent in doc]\n",
    "    idx_dict = \\\n",
    "    [[word_to_idx_dict[word] if word in word_to_idx_dict.keys() else 0 for word in sent]\\\n",
    "     for sent in min_freq_ls] #if there is no tokens which match with  test datasets vocab then, that token is changed into UNK token\n",
    "    return idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = [word_to_idx(batch[0]) for batch in x_train]\n",
    "test_X = [word_to_idx(batch[0]) for batch in x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_sent_len : 한 문서가 가지는 최대 문장 갯수이자, 최소 문장 갯수입니다.(패딩 적용)\n",
    "- max_seq_len : 한 문장이 가지는 최대 단어 갯수이자, 최소 단어 갯수입니다. (패딩 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Padding the number of sentence\n",
    "train_X = [doc + [[1]]*(max_sent_len - len(doc)) if len(doc) <= max_sent_len else doc[:max_sent_len]\\\n",
    "           for doc in train_X]\n",
    "test_X = [doc + [[1]]*(max_sent_len - len(doc)) if len(doc) <= max_sent_len else doc[:max_sent_len]\\\n",
    "           for doc in test_X]\n",
    "\n",
    "## Padding the number of word\n",
    "train_X = [[sent + [1] * (max_seq_len - len(sent)) for sent in doc] for doc in train_X]\n",
    "test_X = [[sent + [1] * (max_seq_len - len(sent)) for sent in doc] for doc in test_X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Datasets with iterators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 문장 안에 있는 단어의 길이 :  {25}\n",
      "한 문서 안에 있는 문장의 길이 :  {12}\n"
     ]
    }
   ],
   "source": [
    "print(\"한 문장 안에 있는 단어의 길이 : \",set([len(sent) for doc in train_X for sent in doc]))\n",
    "print(\"한 문서 안에 있는 문장의 길이 : \",set([len(doc) for doc in train_X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 뒤에 나오는 DataLoader는 Cuda Tensor를 지원하지 않습니다.\n",
    "train_X = torch.LongTensor(train_X)\n",
    "train_y = torch.LongTensor(y_train.tolist())\n",
    "test_X = torch.LongTensor(test_X)\n",
    "test_y = torch.LongTensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([670000, 12, 25]),\n",
       " torch.Size([670000]),\n",
       " torch.Size([330000, 12, 25]),\n",
       " torch.Size([330000]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(train_X,'train_X.pt')\n",
    "torch.save(train_y,'train_y.pt')\n",
    "\n",
    "torch.save(test_X,'test_X.pt')\n",
    "torch.save(test_y,'test_y.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 만약 커널을 끄고 다시 시작하실 경우, 여기서부터 진행하면 됩니다!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_idx_dict = load_obj('word_to_idx_dict')\n",
    "word_to_freq_dict = load_obj('word_to_freq_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = torch.load('train_X.pt')\n",
    "train_y = torch.load('train_y.pt')\n",
    "test_X = torch.load('test_X.pt')\n",
    "test_y = torch.load('test_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        'Initialization'\n",
    "        self.y = y\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 100,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 10}\n",
    "\n",
    "# Generators\n",
    "training_set = Dataset(train_X,train_y)\n",
    "train_iter = data.DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = Dataset(test_X,test_y)\n",
    "test_iter = data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for local_batch, local_labels in train_iter:\n",
    "    local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 12, 25]), torch.Size([100]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_batch.size(),local_labels.size()\n",
    "#[batch_size, sent_len, word_len]\n",
    "# 25개의 단어를 가지고 12개의 문장을 가진 64개의 문서가 있는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained GloVe Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract word embeddings from the Glove\n",
    "embeddings_index = dict()\n",
    "f = open('glove.twitter.27B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어의 길이 170007 개에서 GloVe 벡터로 초기화된 단어의 갯수는 83087 개입니다.\n"
     ]
    }
   ],
   "source": [
    "matrix_len = len(word_to_idx_dict)\n",
    "weights_matrix = np.zeros((matrix_len, 200))\n",
    "words_found = 0\n",
    "\n",
    "for i, word in enumerate(word_to_idx_dict.keys()):\n",
    "    try: \n",
    "        weights_matrix[i] = embeddings_index[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(200, ))\n",
    "        \n",
    "print(\"전체 단어의 길이 {} 개에서 GloVe 벡터로 초기화된 단어의 갯수는 {} 개입니다.\".format(len(word_to_idx_dict),words_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170007, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordAttention(nn.Module) : \n",
    "    \n",
    "    def __init__(self,batch_size,hidden_size) : \n",
    "        \n",
    "        super(WordAttention,self).__init__() \n",
    "        self.batch_size = batch_size\n",
    "        self.linear = nn.Linear(hidden_size*2,hidden_size*2).to(device)\n",
    "        self.word_proj_params = nn.Parameter(torch.Tensor(hidden_size*2,1)).to(device)\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self) : \n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.word_proj_params)\n",
    "        \n",
    "    def forward(self,outputs) : \n",
    "        \n",
    "        outputs = outputs.permute(1,0,2) #[batch_size, sent_len, hidden_dim*2]\n",
    "\n",
    "        u = torch.tanh(self.linear(outputs)) #[batch_size, sent_len, hidden_dim*2]  \n",
    "        word_proj_params = self.word_proj_params.expand(self.batch_size,-1,-1) #[batch_size,hidden_dim*2,1]\n",
    "    \n",
    "        atten = torch.bmm(u,word_proj_params) #[batch_size,sent_len,1]\n",
    "        a = torch.softmax(atten,dim=1) #[batch_size,sent_len,1]\n",
    "        s = torch.sum(torch.mul(a,outputs),dim=1) #[batch_size,hidden_dim*2]\n",
    "        \n",
    "        return s,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim,padding_idx = 1) # <pad>\n",
    "    emb_layer.weight = nn.Parameter(torch.tensor(weights_matrix,dtype=torch.float32))\n",
    "    \n",
    "    return emb_layer\n",
    "    \n",
    "class WordRNN(nn.Module) : \n",
    "    \n",
    "    def __init__(self,batch_size,vocab_size,embed_size,hidden_size,num_layer,max_sent_len,weights_matrix) : \n",
    "        \n",
    "        super(WordRNN,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.gru_hidden_size = hidden_size\n",
    "        self.num_layer = num_layer\n",
    "        self.max_sent_len = max_sent_len\n",
    "#         self.embeddings = nn.Embedding(vocab_size,embed_size,padding_idx = 1).to(device)\n",
    "        self.embeddings = create_emb_layer(weights_matrix).to(device)\n",
    "        # GloVe 로 Initialize만 시키고, Training이 가능하게 해줍니다.\n",
    "        self.gru = nn.GRU(embed_size,hidden_size,num_layer,bidirectional=True).to(device)\n",
    "        \n",
    "        self.word_atten = WordAttention(batch_size,hidden_size).to(device)\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self) : \n",
    "        for layer_p in gru._all_weights:\n",
    "            for p in layer_p:\n",
    "                if 'weight' in p:\n",
    "                    nn.init.xavier_normal_(gru.__getattr__(p),)\n",
    "\n",
    "    def forward(self,input_,hidden) : \n",
    "        \n",
    "        sent_vec_ls = []; word_attention_ls = []\n",
    "        \n",
    "        for i in range(self.max_sent_len) : \n",
    "            x = input_[:,i,:]  # x : [batch_size, T :(word length per sentence)]\n",
    "            embeds = self.embeddings(x).permute(1,0,2) # [T, batch_size, embed_dim] \n",
    "\n",
    "            outputs, hidden = self.gru(embeds,hidden)\n",
    "            \n",
    "            sent_vec,word_attention = self.word_atten(outputs)\n",
    "        \n",
    "            sent_vec_ls.append(sent_vec.unsqueeze(1))\n",
    "            word_attention_ls.append(word_attention.permute(0,2,1))\n",
    "        \n",
    "        sent_vec = torch.cat(sent_vec_ls,dim=1)\n",
    "        word_attention = torch.cat(word_attention_ls,dim=1)\n",
    "                \n",
    "        return sent_vec,word_attention,hidden\n",
    "    # [batch_size,sent_len,hidden_size]\n",
    "    # [batch_size,sent_len,word_len]\n",
    "    # [num_layer*bidirectional(2), batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "vocab_size = len(word_to_idx_dict)\n",
    "embed_size = 200\n",
    "hidden_size = 50\n",
    "num_layer = 1\n",
    "max_sent_len = 12\n",
    "\n",
    "word_model = WordRNN(batch_size,vocab_size,embed_size,hidden_size,num_layer,max_sent_len,weights_matrix)\n",
    "hidden = \\\n",
    "        Variable(torch.randn(num_layer*2, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_vec,word_attention,hidden = word_model(local_batch,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentAttention(nn.Module) : \n",
    "    \n",
    "    def __init__(self,batch_size,hidden_size) : \n",
    "        \n",
    "        super(SentAttention,self).__init__() \n",
    "        self.batch_size = batch_size\n",
    "        self.linear = nn.Linear(hidden_size*2,hidden_size*2).to(device)\n",
    "        self.sent_proj_params = nn.Parameter(torch.Tensor(hidden_size*2,1)).to(device)\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self) : \n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.sent_proj_params)\n",
    "        \n",
    "    def forward(self,outputs) : \n",
    "        \n",
    "        outputs = outputs.permute(1,0,2) #[batch_size, doc_len, hidden_dim*2]\n",
    "        u = torch.tanh(self.linear(outputs)) #[batch_size, doc_len, hidden_dim*2]\n",
    "        sent_proj_params = self.sent_proj_params.expand(self.batch_size,-1,-1) #[batch_size,hidden_dim*2,1]\n",
    "        atten = torch.bmm(u,sent_proj_params) #[batch_size,doc_len,1]\n",
    "        a = torch.softmax(atten,dim=1) #[batch_size,doc_len,1]\n",
    "        v = torch.sum(a * outputs,dim=1) #[batch_size,hidden_dim*2]\n",
    "        return v,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentRNN(nn.Module) : \n",
    "    \n",
    "    def __init__(self,batch_size,vocab_size,embed_size,hidden_size,num_layer) : \n",
    "        \n",
    "        super(SentRNN,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.gru_hidden_size = hidden_size\n",
    "        self.num_layer = num_layer\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size*2,hidden_size,num_layer,bidirectional=True).to(device)\n",
    "        \n",
    "        self.sent_atten = SentAttention(batch_size,hidden_size)\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self) : \n",
    "        for layer_p in gru._all_weights:\n",
    "            for p in layer_p:\n",
    "                if 'weight' in p:\n",
    "                    nn.init.xavier_normal_(gru.__getattr__(p),)\n",
    "\n",
    "    def forward(self,x,hidden) : \n",
    "        \n",
    "        x = x.permute(1,0,2) #x : [doc_len,batch_size, hidden*2]\n",
    "\n",
    "        outputs, hidden = self.gru(x,hidden)\n",
    "    \n",
    "        doc_vec,sent_attention = self.sent_atten(outputs)\n",
    "        \n",
    "        return doc_vec,sent_attention,hidden\n",
    "    \n",
    "    #[batch_size,hidden_dim*2]\n",
    "    #[batch_size,doc_len,1]\n",
    "    #[num_layer*2,batch_size,hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_model = SentRNN(batch_size,vocab_size,embed_size,hidden_size,num_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vec,sent_attention,hidden = sent_model(sent_vec,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HAN(nn.Module) : \n",
    "    \n",
    "    def __init__(self,batch_size,vocab_size,embed_size,hidden_size,num_layer,max_sent_len,num_class,weights_matrix) : \n",
    "        \n",
    "        super(HAN,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layer\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.num_class = num_class\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "        self.word_encoder =\\\n",
    "        WordRNN(batch_size,vocab_size,embed_size,hidden_size,num_layer,max_sent_len,weights_matrix).to(self.device)\n",
    "        \n",
    "        self.sent_encoder =\\\n",
    "        SentRNN(batch_size,vocab_size,embed_size,hidden_size,num_layer).to(self.device)\n",
    "        \n",
    "        self.proj_layer = nn.Linear(hidden_size*2,num_class).to(self.device)\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self) : \n",
    "        torch.nn.init.xavier_uniform_(self.proj_layer.weight)\n",
    "        \n",
    "    def init_hidden(self,batch_size):\n",
    "        hidden = \\\n",
    "        Variable(torch.zeros(self.num_layers*2, batch_size, self.hidden_size, device=self.device))\n",
    "            \n",
    "        return hidden\n",
    "    \n",
    "    def forward(self,input_) : \n",
    "        \n",
    "        (batch_size,sent_len,doc_len) = input_.size()\n",
    "        \n",
    "        word_encoder_hidden = self.init_hidden(batch_size)\n",
    "        sent_vec,word_attention,hidden = self.word_encoder(input_,word_encoder_hidden)\n",
    "        sent_vec = nn.LayerNorm(self.hidden_size*2).to(device)(sent_vec)\n",
    "        \n",
    "        sent_encoder_hidden = self.init_hidden(batch_size)\n",
    "        doc_vec,sent_attention,hidden = self.sent_encoder(sent_vec,sent_encoder_hidden)\n",
    "        doc_vec = nn.LayerNorm(self.hidden_size*2).to(device)(doc_vec)\n",
    "        \n",
    "        logit = self.proj_layer(doc_vec)\n",
    "        log_softmax = torch.log_softmax(logit,dim=1)\n",
    "        \n",
    "        return log_softmax, word_attention, sent_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAN(\n",
       "  (word_encoder): WordRNN(\n",
       "    (embeddings): Embedding(170007, 200, padding_idx=1)\n",
       "    (gru): GRU(200, 50, bidirectional=True)\n",
       "    (word_atten): WordAttention(\n",
       "      (linear): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sent_encoder): SentRNN(\n",
       "    (gru): GRU(100, 50, bidirectional=True)\n",
       "    (sent_atten): SentAttention(\n",
       "      (linear): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_layer): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'batch_size' : 100,\n",
    "'vocab_size' : len(word_to_idx_dict),\n",
    "'embed_size' : 200,\n",
    "'hidden_size' : 50,\n",
    "'num_layer' : 1,\n",
    "'max_sent_len' : 12,       \n",
    "'num_class' : 5,\n",
    "'weights_matrix' : weights_matrix,\n",
    "}\n",
    "\n",
    "model = HAN(**params).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_softmax, word_attention, sent_attention = model(local_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr=0.1, decay = 0.1 ,per_epoch=10):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= 1/(1 + decay)\n",
    "\n",
    "    return optimizer , float(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader , test_loader , epochs = 10, lr = 0.01, batch_size = 100) :\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "    for epoch in range(1,epochs+1) :\n",
    "        optimizer , lr_int = \\\n",
    "        adjust_learning_rate(optimizer, epoch, init_lr=lr, decay = 0.1 ,per_epoch=10)\n",
    "        model.train()        \n",
    "        n_correct = 0\n",
    "        batch_count = 0\n",
    "        for local_batch, local_labels in train_loader:\n",
    "            \n",
    "            batch_count += 1 \n",
    "            if batch_count % 1000 == 0 : \n",
    "                print(\"{}번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\".format(batch_count))\n",
    "                \n",
    "            local_batch,local_labels = local_batch.to(device),local_labels.to(device)\n",
    "        \n",
    "            train_softmax, word_attention, sent_attention = model(local_batch)\n",
    "            train_predict = train_softmax.argmax(dim=1)\n",
    "\n",
    "            n_correct += (train_predict == local_labels).sum().item()            \n",
    "            loss = criterion(train_softmax,local_labels)\n",
    "            \n",
    "            if loss.item() == 'nan' : \n",
    "                return local_batch,local_labels,train_softmax,word_attention,sent_attention\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        acc = n_correct / (len(train_loader) * batch_size)  \n",
    "        with open('log.txt', 'a') as f:\n",
    "            f.write('Train epoch : %s,  loss : %s,  accuracy :%.3f, learning rate :%.3f\\n\\n'%(epoch, loss.item(), acc,lr_int))\n",
    "            \n",
    "        print('Train epoch : %s,  loss : %s,  accuracy :%.3f, learning rate :%.3f'%(epoch, loss.item(), acc,lr_int))\n",
    "        print('=================================================================================================')\n",
    "        \n",
    "        if (epoch) % 2 == 0:\n",
    "            model.eval()\n",
    "            n_correct = 0  # accuracy 계산을 위해 맞은 갯수 카운트\n",
    "            val_loss = 0\n",
    "\n",
    "            for local_batch, local_labels in test_loader:\n",
    "                local_batch,local_labels = local_batch.to(device),local_labels.to(device)\n",
    "                \n",
    "                test_softmax, word_attention, sent_attention = model(local_batch)\n",
    "                test_predict = test_softmax.argmax(dim = 1)\n",
    "\n",
    "                val_loss = criterion(test_softmax, local_labels)\n",
    "                \n",
    "                n_correct += (test_predict == local_labels).sum().item() #맞은 갯수                \n",
    "\n",
    "            val_acc = n_correct / (len(test_loader) * batch_size)\n",
    "            with open('log.txt','a') as f : \n",
    "                f.write('Val Epoch : %s, Val Loss : %.03f , Val Accuracy : %.03f\\n\\n'%(epoch, val_loss, val_acc))\n",
    "                \n",
    "            print('*************************************************************************************************')\n",
    "            print('*************************************************************************************************')\n",
    "            print('Val Epoch : %s, Val Loss : %.03f , Val Accuracy : %.03f'%(epoch, val_loss, val_acc))\n",
    "            print('*************************************************************************************************')\n",
    "            print('*************************************************************************************************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 1,  loss : 0.7867679595947266,  accuracy :0.658, learning rate :0.009\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 2,  loss : 0.6004376411437988,  accuracy :0.665, learning rate :0.008\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 2, Val Loss : 0.686 , Val Accuracy : 0.659\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 3,  loss : 0.8486897945404053,  accuracy :0.668, learning rate :0.008\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 4,  loss : 0.6839591264724731,  accuracy :0.671, learning rate :0.007\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 4, Val Loss : 0.830 , Val Accuracy : 0.663\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 5,  loss : 0.723807156085968,  accuracy :0.673, learning rate :0.006\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 6,  loss : 0.7063800692558289,  accuracy :0.675, learning rate :0.006\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 6, Val Loss : 0.832 , Val Accuracy : 0.658\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 7,  loss : 0.7294747829437256,  accuracy :0.677, learning rate :0.005\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 8,  loss : 0.7387301921844482,  accuracy :0.678, learning rate :0.005\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 8, Val Loss : 0.978 , Val Accuracy : 0.665\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 9,  loss : 0.8197939991950989,  accuracy :0.680, learning rate :0.004\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 10,  loss : 0.8035174608230591,  accuracy :0.681, learning rate :0.004\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 10, Val Loss : 0.685 , Val Accuracy : 0.666\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 11,  loss : 0.8112872838973999,  accuracy :0.682, learning rate :0.004\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 12,  loss : 0.7385613918304443,  accuracy :0.683, learning rate :0.003\n",
      "=================================================================================================\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 12, Val Loss : 0.806 , Val Accuracy : 0.666\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 13,  loss : 0.8115079402923584,  accuracy :0.686, learning rate :0.003\n",
      "=================================================================================================\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "3000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "4000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "5000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "6000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "Train epoch : 14,  loss : 0.766478419303894,  accuracy :0.687, learning rate :0.003\n",
      "=================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "Val Epoch : 14, Val Loss : 0.747 , Val Accuracy : 0.670\n",
      "*************************************************************************************************\n",
      "*************************************************************************************************\n",
      "1000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n",
      "2000번째 배치가 돌고 있습니다. 한 에포크는 6700입니다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0d7380220347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocal_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_softmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent_attention\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-863d687ac4e0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtrain_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mtrain_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-1e5be1e931c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mword_encoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msent_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_encoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0msent_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-707eb770f29b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, hidden)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [T, batch_size, embed_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0msent_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_atten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "local_batch,local_labels,train_softmax,word_attention,sent_attention = \\\n",
    "train(model, train_iter, test_iter, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fin/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type HAN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/fin/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type WordRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/fin/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type WordAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/fin/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type SentRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/fin/anaconda3/envs/engine_3.6/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type SentAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,'HAN.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` params = {'batch_size' : 100,\n",
    "'vocab_size' : len(word_to_idx_dict),\n",
    " 'embed_size' : 128,\n",
    " 'hidden_size' : 100,\n",
    " 'num_layer' : 1,\n",
    " 'max_sent_len' : 12,       \n",
    " 'num_class' : 5}`\n",
    "\n",
    "**Highest Validation Accuracy at Epoch 15 without pretrained embedding and Layer Normalization BUT there was no weight initialization such as xavier so, word attention wasn't changed and NaN values are appeared sometimes: 0.59**\n",
    "____________________\n",
    "`params = {'batch_size' : 100,\n",
    " 'vocab_size' : len(word_to_idx_dict),\n",
    " 'embed_size' : 200,\n",
    " 'hidden_size' : 50,\n",
    " 'num_layer' : 1,\n",
    " 'max_sent_len' : 12,       \n",
    " 'num_class' : 5\n",
    " }`\n",
    "\n",
    " **Highest Validation Accuracy at Epoch 15 : 0.40**\n",
    " ____________________\n",
    " ` params = {'batch_size' : 100,\n",
    "'vocab_size' : len(word_to_idx_dict),\n",
    " 'embed_size' : 128,\n",
    " 'hidden_size' : 100,\n",
    " 'num_layer' : 1,\n",
    " 'max_sent_len' : 12,       \n",
    " 'num_class' : 5}`\n",
    "\n",
    "**Highest Validation Accuracy at Epoch 15 without pretrained embedding and Layer Normalization with xavier weight normalization: 0.67**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implication\n",
    "- 최종 test accuracy는 약 60퍼센트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_iter))\n",
    "X = batch[0].cuda(); y = batch[1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_softmax, word_attention, sent_attention = model(X.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 배치 사이즈에 대한 Accuracy는 70.0 % 입니다.\n"
     ]
    }
   ],
   "source": [
    "correct_ratio = (log_softmax.argmax(dim=1) == y).sum().item() / batch_size\n",
    "\n",
    "print(\"한 배치 사이즈에 대한 Accuracy는 {} % 입니다.\".format(correct_ratio*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_ls = [[idx_to_word_dict[word.item()] for word in sent if word != 1]for sent in X[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_attn_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>this place was a disappointment and way overpriced !</th>\n",
       "      <td>0.125161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfortunately   it was horrible ! ! !</th>\n",
       "      <td>0.123758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the pork came with beans and they were way too salty</th>\n",
       "      <td>0.121092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the pork tasted like it was a day old and it was</th>\n",
       "      <td>0.098670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we also ordered the caesar salad and it was doused with dressing</th>\n",
       "      <td>0.098664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had to ask for a replacement with dressing on the side</th>\n",
       "      <td>0.098221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my wife got the kailua pig as it was also recommended</th>\n",
       "      <td>0.071795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the service was the best part of the meal</th>\n",
       "      <td>0.071777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so   we were told the calamari is very fresh and has</th>\n",
       "      <td>0.069570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it did taste very good and we were excited for our dinner</th>\n",
       "      <td>0.069570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.025836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sent_attn_score\n",
       "this place was a disappointment and way overpri...         0.125161\n",
       "unfortunately   it was horrible ! ! !                      0.123758\n",
       "the pork came with beans and they were way too ...         0.121092\n",
       "the pork tasted like it was a day old and it was           0.098670\n",
       "we also ordered the caesar salad and it was dou...         0.098664\n",
       "had to ask for a replacement with dressing on t...         0.098221\n",
       "my wife got the kailua pig as it was also recom...         0.071795\n",
       "the service was the best part of the meal                  0.071777\n",
       "so   we were told the calamari is very fresh an...         0.069570\n",
       "it did taste very good and we were excited for ...         0.069570\n",
       "                                                           0.025836"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(\\\n",
    "    dict(zip([','.join(sent).replace(\",\",' ') for sent in doc_ls],\\\n",
    "         [i.item() for i in sent_attention[0]])),orient='index',columns=['sent_attn_score'])\\\n",
    "            .sort_values('sent_attn_score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coloring to word and sentence under Attention score\n",
    "\n",
    "- **Text colors** :\n",
    "    - grey : relative influencial word in positive sentence (first quatile)\n",
    "    - red : relative influencial word in negative sentence (first quatile)\n",
    "    - green : relative non-influencial word in sentence \n",
    "    \n",
    "- **Text highlights** :\n",
    "    - on_grey : relative influencial word in positive doc (first quatile)\n",
    "    - on_red : relative influencial word in negative doc (first quatile)\n",
    "    - on_green : relative non-influencial word in doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coloring(model,X,y,index,sent_attention,word_attention,first_threshold=80,second_treshold=60) : \n",
    "    \n",
    "    sent_ls = np.array([idx_to_word_dict[word.item()] for sent in X[index] for word in sent])\n",
    "    sent_attention_ls = np.array([i[0].item() for i in sent_attention[index] for _ in range(25)])\n",
    "    word_attention_ls = np.array([j.item() for i in word_attention[index] for j in i])\n",
    "\n",
    "    first_sent_attn_threshold = np.percentile(sent_attention_ls,first_threshold)\n",
    "    first_word_attn_threshold = np.percentile(word_attention_ls,first_threshold)\n",
    "\n",
    "    second_sent_attn_threshold = np.percentile(sent_attention_ls,second_treshold)\n",
    "\n",
    "    colored_doc = []\n",
    "\n",
    "    for word,sent_attn,word_attn in zip(sent_ls,sent_attention_ls,word_attention_ls) : \n",
    "        color_ls = ''\n",
    "        if word == '<pad>' : continue\n",
    "        if sent_attn > first_sent_attn_threshold : \n",
    "            color_ls = 'green'\n",
    "            if word_attn > first_word_attn_threshold : \n",
    "                colored_doc.append(colored(word,color_ls,attrs=['underline']))\n",
    "            else : colored_doc.append(colored(word,color_ls))\n",
    "        elif sent_attn > second_sent_attn_threshold : \n",
    "            color_ls = 'yellow'\n",
    "            if word_attn > first_word_attn_threshold : \n",
    "                colored_doc.append(colored(word,color_ls,attrs=['underline']))\n",
    "            else : colored_doc.append(colored(word,color_ls))\n",
    "        else : \n",
    "            color_ls = 'grey'\n",
    "            if word_attn > first_word_attn_threshold : \n",
    "                colored_doc.append(colored(word,color_ls,attrs=['underline']))\n",
    "            else : colored_doc.append(colored(word,color_ls))\n",
    "                \n",
    "    for i in colored_doc : \n",
    "        print(i,end=' ')\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    display(Markdown('### The true label is {} and our model predicts the label {}.\\\n",
    "    If the model misclassifies the label, then the annotation might be also wrong.'\\\n",
    "         .format(y[index].item(),(model(X)[0].argmax(1) == y)[index].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[30mso\u001b[0m \u001b[30m,\u001b[0m \u001b[30mwe\u001b[0m \u001b[30mwere\u001b[0m \u001b[4m\u001b[30mtold\u001b[0m \u001b[30mthe\u001b[0m \u001b[4m\u001b[30mcalamari\u001b[0m \u001b[30mis\u001b[0m \u001b[4m\u001b[30mvery\u001b[0m \u001b[30mfresh\u001b[0m \u001b[30mand\u001b[0m \u001b[30mhas\u001b[0m \u001b[30mit\u001b[0m \u001b[30mdid\u001b[0m \u001b[30mtaste\u001b[0m \u001b[4m\u001b[30mvery\u001b[0m \u001b[4m\u001b[30mgood\u001b[0m \u001b[30mand\u001b[0m \u001b[30mwe\u001b[0m \u001b[30mwere\u001b[0m \u001b[4m\u001b[30mexcited\u001b[0m \u001b[30mfor\u001b[0m \u001b[30mour\u001b[0m \u001b[30mdinner\u001b[0m \u001b[30mmy\u001b[0m \u001b[4m\u001b[30mwife\u001b[0m \u001b[30mgot\u001b[0m \u001b[30mthe\u001b[0m \u001b[4m\u001b[30mkailua\u001b[0m \u001b[30mpig\u001b[0m \u001b[4m\u001b[30mas\u001b[0m \u001b[30mit\u001b[0m \u001b[30mwas\u001b[0m \u001b[30malso\u001b[0m \u001b[4m\u001b[30mrecommended\u001b[0m \u001b[4m\u001b[33munfortunately\u001b[0m \u001b[33m,\u001b[0m \u001b[33mit\u001b[0m \u001b[4m\u001b[33mwas\u001b[0m \u001b[4m\u001b[33mhorrible\u001b[0m \u001b[33m!\u001b[0m \u001b[33m!\u001b[0m \u001b[33m!\u001b[0m \u001b[33mthe\u001b[0m \u001b[33mpork\u001b[0m \u001b[4m\u001b[33mtasted\u001b[0m \u001b[33mlike\u001b[0m \u001b[33mit\u001b[0m \u001b[33mwas\u001b[0m \u001b[33ma\u001b[0m \u001b[33mday\u001b[0m \u001b[33mold\u001b[0m \u001b[33mand\u001b[0m \u001b[33mit\u001b[0m \u001b[33mwas\u001b[0m \u001b[33mthe\u001b[0m \u001b[33mpork\u001b[0m \u001b[33mcame\u001b[0m \u001b[33mwith\u001b[0m \u001b[33mbeans\u001b[0m \u001b[33mand\u001b[0m \u001b[33mthey\u001b[0m \u001b[33mwere\u001b[0m \u001b[33mway\u001b[0m \u001b[4m\u001b[33mtoo\u001b[0m \u001b[4m\u001b[33msalty\u001b[0m \u001b[4m\u001b[30mwe\u001b[0m \u001b[4m\u001b[30malso\u001b[0m \u001b[4m\u001b[30mordered\u001b[0m \u001b[30mthe\u001b[0m \u001b[30mcaesar\u001b[0m \u001b[30msalad\u001b[0m \u001b[30mand\u001b[0m \u001b[30mit\u001b[0m \u001b[30mwas\u001b[0m \u001b[30mdoused\u001b[0m \u001b[30mwith\u001b[0m \u001b[4m\u001b[30mdressing\u001b[0m \u001b[30mhad\u001b[0m \u001b[30mto\u001b[0m \u001b[4m\u001b[30mask\u001b[0m \u001b[30mfor\u001b[0m \u001b[30ma\u001b[0m \u001b[4m\u001b[30mreplacement\u001b[0m \u001b[30mwith\u001b[0m \u001b[4m\u001b[30mdressing\u001b[0m \u001b[30mon\u001b[0m \u001b[30mthe\u001b[0m \u001b[4m\u001b[30mside\u001b[0m \u001b[32mthis\u001b[0m \u001b[32mplace\u001b[0m \u001b[32mwas\u001b[0m \u001b[32ma\u001b[0m \u001b[4m\u001b[32mdisappointment\u001b[0m \u001b[32mand\u001b[0m \u001b[4m\u001b[32mway\u001b[0m \u001b[4m\u001b[32moverpriced\u001b[0m \u001b[32m!\u001b[0m \u001b[30mthe\u001b[0m \u001b[30mservice\u001b[0m \u001b[4m\u001b[30mwas\u001b[0m \u001b[30mthe\u001b[0m \u001b[4m\u001b[30mbest\u001b[0m \u001b[4m\u001b[30mpart\u001b[0m \u001b[30mof\u001b[0m \u001b[30mthe\u001b[0m \u001b[30mmeal\u001b[0m \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### The true label is 0 and our model predicts the label 0.    If the model misclassifies the label, then the annotation might be also wrong."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coloring(model,X,y,0,sent_attention,word_attention,first_threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
